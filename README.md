# urop-ml-prediction-deformation

## Description

This repository contains the code I used to build the pre-correction model for Sara's Chinese Character dataset. There are three folders:

#### process_scans

This folder contains code to process the CT scans taken of the 3D-printed Chinese Characters.

Before running this, I segmented the scans in VGStudio and manually cropped each individual chinese character into its own image (although modifying crop.py, written by Sara for her scans, could also be used for this).

`run.py` operates on these black-and-white images of the individual characters, and runs the rest of the dataset preparation pipeline as explained in Figure 6 of my report. That means it:
- extracts the nominal 'CAD' shape from the imgaes in the nominal_fonts folder
- scales it up and pads to match the scale factor and resolution of the scan image
- aligns the scan image to the CAD image by minimising the cross-correlation
- makes a heatmap comparing the gained and lost material between the nominal (CAD) and 3D-printed (scan) images, and counts these lost and gained pixels as a proportion of the pixels in the CAD character

Note: This code is very similar to the code I used to process the surgical guides. The files of the form _<>.py should be identical to those in the surgical guide GitHub repo.

#### neuralnet

This folder contains code to train the neural networks. It can train on the dataset in the ChineseCharacterDataset folder, which was created using the scan and CAD images generated by the code in the process_scans folder (above).

`experiment.py` chooses a model, loads the dataset, selects the hyperparameters and trains the model.
`demonstrate_model.py` displays the results. It can also generate thresholded, pre-corrected images that the code in the precorrect folder operates on.

#### precorrect

This folder contains code to generate precorrected STL files from the precorrected images taken from the neural network output, i.e. inclduing the inverse source transform mentioned in my report.

## Getting Started

### Dependencies

I ran the code in Windows 11 Anaconda, using the modules contained in `environment.yml`. Also needed is pytorch (optionally alongside Nvidia CUDA).

Set up the environment by, in anaconda terminal in repository folder, executing `conda env create -f environment.yml` (this might take a while to install everything). It will create an environment called my_ccml_env, or whatever you change the first line to in `environment.yml`.
